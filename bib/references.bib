@article{article,
  author = {Courtial, Azelle and Touya, Guillaume and Zhang, Xiang},
  year = {2022},
  month = {06},
  pages = {},
  title = {Constraint-Based Evaluation of Map Images Generalized by Deep Learning},
  volume = {6},
  journal = {Journal of Geovisualization and Spatial Analysis},
  doi = {10.1007/s41651-022-00104-2},
  keywords = {gans, map_generation, maps}
}

@misc{chen2023text2tex,
  title = {Text2Tex: Text-driven Texture Synthesis via Diffusion Models},
  author = {Dave Zhenyu Chen and Yawar Siddiqui and Hsin-Ying Lee and Sergey Tulyakov and Matthias Nießner},
  year = {2023},
  eprint = {2303.11396},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV},
  keywords = {Chat_Bot, Diffusion_Model, generative_image_synthesis}
}

@article{christophe2022neural,
  title = {Neural map style transfer exploration with GANs},
  author = {Christophe, Sidonie and Mermet, Samuel and Laurent, Morgan and Touya, Guillaume},
  journal = {International Journal of Cartography},
  volume = {8},
  number = {1},
  pages = {18--36},
  year = {2022},
  publisher = {Taylor \& Francis},
  keywords = {gans, computer_vision, style_transfer , maps}
}

@misc{crowson2022vqganclip,
  title = {VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance},
  author = {Katherine Crowson and Stella Biderman and Daniel Kornis and Dashiell Stander and Eric Hallahan and Louis Castricato and Edward Raff},
  year = {2022},
  eprint = {2204.08583},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV},
  keywords = {chat_bot, difusion_model, diffusion_model, Generative_image_synthesis}
}

@misc{fu2018geometryconsistent,
  title = {Geometry-Consistent Generative Adversarial Networks for One-Sided Unsupervised Domain Mapping},
  author = {Huan Fu and Mingming Gong and Chaohui Wang and Kayhan Batmanghelich and Kun Zhang and Dacheng Tao},
  year = {2018},
  eprint = {1809.05852},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV},
  keywords = {GANs, computer_vision, generative_image_synthesis, maps}
}

@misc{goodfellow2014generative,
  title = {Generative Adversarial Networks},
  author = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year = {2014},
  eprint = {1406.2661},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML},
  keywords = {gans, generative_image_synthesis}
}

@inproceedings{kang2020towards,
  title = {Towards cartographic knowledge encoding with deep learning: A case study of building generalization},
  author = {Kang, Y and Rao, J and Wang, W and Peng, B and Gao, S and Zhang, F},
  booktitle = {Proceedings of the AutoCarto},
  year = {2020},
  keywords = {maps, map_generation, gans}
}

@misc{lin2023infinicity,
  title = {InfiniCity: Infinite-Scale City Synthesis},
  author = {Chieh Hubert Lin and Hsin-Ying Lee and Willi Menapace and Menglei Chai and Aliaksandr Siarohin and Ming-Hsuan Yang and Sergey Tulyakov},
  year = {2023},
  eprint = {2301.09637},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV},
  keywords = {maps, map_generation, gans, cnn}
}

@misc{rombach2022highresolution,
  title = {High-Resolution Image Synthesis with Latent Diffusion Models},
  author = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  year = {2022},
  eprint = {2112.10752},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV},
  keywords = {diffusion_model, generative_image_synthesis, autoencoders}
}

@article{rs14040919,
  author = {Song, Jieqiong and Li, Jun and Chen, Hao and Wu, Jiangjiang},
  title = {RSMT: A Remote Sensing Image-to-Map Translation Model via Adversarial Deep Transfer Learning},
  journal = {Remote Sensing},
  volume = {14},
  year = {2022},
  number = {4},
  article-number = {919},
  url = {https://www.mdpi.com/2072-4292/14/4/919},
  issn = {2072-4292},
  abstract = {Maps can help governments in infrastructure development and emergency rescue operations around the world. Using adversarial learning to generate maps from remote sensing images is an emerging field. As we now know, the urban construction styles of different cities are diverse. The current translation methods for remote sensing image-to-map tasks only work on the specific regions with similar styles and structures to the training set and perform poorly on previously unseen areas. We argue that this greatly limits their use. In this work, we intend to seek a remote sensing image-to-map translation model that approaches the challenge of generating maps for the remote sensing images of unseen areas. Our remote sensing image-to-map translation model (RSMT) achieves universal and general applicability to generate maps over multiple regions by combining adversarial deep transfer training schemes with novel attention-based network designs. Extracting the content and style latent features from remote sensing images and a series of maps, respectively, RSMT generalizes a pattern applied to the remote sensing images of new areas. Meanwhile, we introduce feature map loss and map consistency loss to reinforce generated maps&rsquo; precision and geometry similarity. We critically analyze qualitative and quantitative results using widely adopted evaluation metrics through extensive validation and comparisons with previous remote sensing image-to-map approaches. The results of experiment indicate that RSMT can translate remote sensing images to maps better than several state-of-the-art methods.},
  doi = {10.3390/rs14040919},
  keywords = {maps, map_generation, gans, generative_image_synthesis}
}

